{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPre46w3kcj777FanH4I04o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khushkataruka/Machine-Learning-SVNIT/blob/main/ML_LAB_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# Q1: Decision Tree (ID3 & C4.5) on playCricket.csv\n",
        "# ==========================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"playCricket.csv\")\n",
        "data.head()\n",
        "\n",
        "# Convert continuous columns to boolean if any (classification task)\n",
        "for col in data.columns[:-1]:\n",
        "    if data[col].dtype != 'object':\n",
        "        thr = data[col].median()\n",
        "        data[col] = (data[col] > thr).astype(str)\n",
        "\n",
        "# Helper functions\n",
        "def entropy(y):\n",
        "    vals, counts = np.unique(y, return_counts=True)\n",
        "    probs = counts / counts.sum()\n",
        "    return -np.sum(probs * np.log2(probs + 1e-9))\n",
        "\n",
        "def info_gain(X, y, feature):\n",
        "    vals = np.unique(X[feature])\n",
        "    total_entropy = entropy(y)\n",
        "    weighted_entropy = sum((len(X[X[feature]==v]) / len(X)) * entropy(y[X[feature]==v]) for v in vals)\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "def split_gain_ratio(X, y, feature):\n",
        "    vals = np.unique(X[feature])\n",
        "    split_info = -np.sum([(len(X[X[feature]==v])/len(X))*np.log2(len(X[X[feature]==v])/len(X)) for v in vals])\n",
        "    return info_gain(X, y, feature) / (split_info + 1e-9)\n",
        "\n",
        "# ID3 Algorithm\n",
        "def id3(X, y):\n",
        "    if len(np.unique(y)) == 1:\n",
        "        return y.iloc[0]\n",
        "    if len(X.columns) == 0:\n",
        "        return y.mode()[0]\n",
        "    gains = {col: info_gain(X, y, col) for col in X.columns}\n",
        "    best = max(gains, key=gains.get)\n",
        "    tree = {best: {}}\n",
        "    for val in np.unique(X[best]):\n",
        "        subX = X[X[best]==val].drop(columns=[best])\n",
        "        subY = y[X[best]==val]\n",
        "        tree[best][val] = id3(subX, subY)\n",
        "    return tree\n",
        "\n",
        "# C4.5 Algorithm\n",
        "def c45(X, y):\n",
        "    if len(np.unique(y)) == 1:\n",
        "        return y.iloc[0]\n",
        "    if len(X.columns) == 0:\n",
        "        return y.mode()[0]\n",
        "    ratios = {col: split_gain_ratio(X, y, col) for col in X.columns}\n",
        "    best = max(ratios, key=ratios.get)\n",
        "    tree = {best: {}}\n",
        "    for val in np.unique(X[best]):\n",
        "        subX = X[X[best]==val].drop(columns=[best])\n",
        "        subY = y[X[best]==val]\n",
        "        tree[best][val] = c45(subX, subY)\n",
        "    return tree\n",
        "\n",
        "# Simple predict function\n",
        "def predict(tree, sample):\n",
        "    if not isinstance(tree, dict):\n",
        "        return tree\n",
        "    feature = list(tree.keys())[0]\n",
        "    val = sample[feature]\n",
        "    if val in tree[feature]:\n",
        "        return predict(tree[feature][val], sample)\n",
        "    return list(tree[feature].values())[0]\n",
        "\n",
        "# 5-Fold Cross Validation\n",
        "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for algo in [\"ID3\", \"C4.5\"]:\n",
        "    accs = []\n",
        "    for train, test in kf.split(X):\n",
        "        X_train, y_train = X.iloc[train], y.iloc[train]\n",
        "        X_test, y_test = X.iloc[test], y.iloc[test]\n",
        "        tree = id3(X_train, y_train) if algo==\"ID3\" else c45(X_train, y_train)\n",
        "        preds = [predict(tree, row) for _, row in X_test.iterrows()]\n",
        "        accs.append(accuracy_score(y_test, preds))\n",
        "    print(f\"{algo} Accuracy (PlayCricket):\", np.mean(accs))\n"
      ],
      "metadata": {
        "id": "WgW0T8jBtQtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10204866-1edf-468f-f2f3-58a01af38728"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID3 Accuracy (PlayCricket): 0.39999999999999997\n",
            "C4.5 Accuracy (PlayCricket): 0.4666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# Q2: Decision Tree (ID3 & C4.5) on drug_200.csv\n",
        "# ==========================\n",
        "\n",
        "data2 = pd.read_csv(\"drug_200.csv\")\n",
        "data2.head()\n",
        "\n",
        "# Convert numerical columns to boolean if classification\n",
        "for col in data2.columns[:-1]:\n",
        "    if data2[col].dtype != 'object':\n",
        "        thr = data2[col].median()\n",
        "        data2[col] = (data2[col] > thr).astype(str)\n",
        "\n",
        "X, y = data2.iloc[:,:-1], data2.iloc[:,-1]\n",
        "\n",
        "for algo in [\"ID3\", \"C4.5\"]:\n",
        "    accs = []\n",
        "    for train, test in kf.split(X):\n",
        "        X_train, y_train = X.iloc[train], y.iloc[train]\n",
        "        X_test, y_test = X.iloc[test], y.iloc[test]\n",
        "        tree = id3(X_train, y_train) if algo==\"ID3\" else c45(X_train, y_train)\n",
        "        preds = [predict(tree, row) for _, row in X_test.iterrows()]\n",
        "        accs.append(accuracy_score(y_test, preds))\n",
        "    print(f\"{algo} Accuracy (Drug200):\", np.mean(accs))\n"
      ],
      "metadata": {
        "id": "3TbxQ4SivFiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32823e5e-ed4c-4b98-f3c7-136faa5537d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID3 Accuracy (Drug200): 0.8800000000000001\n",
            "C4.5 Accuracy (Drug200): 0.8800000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "331a7966",
        "outputId": "9265c7bf-0ffd-4547-e9bf-ddfff2a76a93"
      },
      "source": [
        "# ==========================\n",
        "# Q3: Decision Tree Regression on petrol_consumption.csv\n",
        "# ==========================\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "data3 = pd.read_csv(\"petrol_consumption.csv\")\n",
        "data3.head()\n",
        "\n",
        "X = data3.iloc[:,:-1].values\n",
        "y = data3.iloc[:,-1].values\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, feat=None, thr=None, left=None, right=None, val=None):\n",
        "        self.feat = feat\n",
        "        self.thr = thr\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.val = val\n",
        "\n",
        "def mse(y):\n",
        "    return np.mean((y - np.mean(y))**2)\n",
        "\n",
        "def best_split(X, y):\n",
        "    best_feat, best_thr, best_gain = None, None, -1\n",
        "    for feat in range(X.shape[1]):\n",
        "        for thr in np.unique(X[:,feat]):\n",
        "            left, right = y[X[:,feat]<=thr], y[X[:,feat]>thr]\n",
        "            if len(left)==0 or len(right)==0: continue\n",
        "            gain = mse(y) - (len(left)/len(y))*mse(left) - (len(right)/len(y))*mse(right)\n",
        "            if gain > best_gain:\n",
        "                best_feat, best_thr, best_gain = feat, thr, gain\n",
        "    return best_feat, best_thr\n",
        "\n",
        "def build_tree(X, y, depth=0, max_depth=5):\n",
        "    if len(np.unique(y))==1 or depth>=max_depth:\n",
        "        return Node(val=np.mean(y))\n",
        "    feat, thr = best_split(X, y)\n",
        "    if feat is None: return Node(val=np.mean(y))\n",
        "    left_idx, right_idx = X[:,feat]<=thr, X[:,feat]>thr\n",
        "    left = build_tree(X[left_idx], y[left_idx], depth+1, max_depth)\n",
        "    right = build_tree(X[right_idx], y[right_idx], depth+1, max_depth)\n",
        "    return Node(feat, thr, left, right)\n",
        "\n",
        "def predict_reg(node, x):\n",
        "    if node.val is not None:\n",
        "        return node.val\n",
        "    if x[node.feat] <= node.thr:\n",
        "        return predict_reg(node.left, x)\n",
        "    else:\n",
        "        return predict_reg(node.right, x)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r2s, rmses = [], []\n",
        "\n",
        "for train, test in kf.split(X):\n",
        "    X_train, y_train = X[train], y[train]\n",
        "    X_test, y_test = X[test], y[test]\n",
        "    tree = build_tree(X_train, y_train)\n",
        "    preds = np.array([predict_reg(tree, x) for x in X_test])\n",
        "    r2s.append(r2_score(y_test, preds))\n",
        "    rmses.append(np.sqrt(mean_squared_error(y_test, preds)))\n",
        "\n",
        "print(\"Regression Decision Tree:\")\n",
        "print(\"Average R2:\", np.mean(r2s))\n",
        "print(\"Average RMSE:\", np.mean(rmses))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Decision Tree:\n",
            "Average R2: -0.15888089862827232\n",
            "Average RMSE: 96.59973085862343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y1PmHvE6Xyx0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}