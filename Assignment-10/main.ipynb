{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be2bc8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "# ===============================\n",
    "# 1ï¸âƒ£ Metric Functions\n",
    "# ===============================\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).flatten()\n",
    "    y_pred = np.asarray(y_pred).flatten()\n",
    "    return float(np.mean(y_true == y_pred))\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "    labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    label_to_idx = {v: i for i, v in enumerate(labels)}\n",
    "    cm = np.zeros((len(labels), len(labels)), dtype=int)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[label_to_idx[t], label_to_idx[p]] += 1\n",
    "    return cm\n",
    "\n",
    "def precision_recall_f1(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    y_true = y_true.astype(int).flatten()\n",
    "    y_pred = y_pred.astype(int).flatten()\n",
    "\n",
    "    labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for label in labels:\n",
    "        tp = np.sum((y_pred == label) & (y_true == label))\n",
    "        fp = np.sum((y_pred == label) & (y_true != label))\n",
    "        fn = np.sum((y_pred != label) & (y_true == label))\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "    return {\n",
    "        \"labels\": labels,\n",
    "        \"precision\": np.array(precisions),\n",
    "        \"recall\": np.array(recalls),\n",
    "        \"f1\": np.array(f1s)\n",
    "    }\n",
    "\n",
    "# ===============================\n",
    "# 2ï¸âƒ£ Image Function\n",
    "# ===============================\n",
    "def array_to_image(arr, size=(28, 28)):\n",
    "    a = np.array(arr).astype(np.uint8).reshape(size)\n",
    "    return Image.fromarray(a)\n",
    "\n",
    "# ===============================\n",
    "# 3ï¸âƒ£ Logistic Regression (Softmax)\n",
    "# ===============================\n",
    "def softmax(z):\n",
    "    z = z - np.max(z, axis=1, keepdims=True)\n",
    "    expz = np.exp(z)\n",
    "    return expz / np.sum(expz, axis=1, keepdims=True)\n",
    "\n",
    "def one_hot(y, k):\n",
    "    oh = np.zeros((len(y), k))\n",
    "    oh[np.arange(len(y)), y] = 1\n",
    "    return oh\n",
    "\n",
    "class SoftmaxRegression:\n",
    "    def __init__(self, n_features, n_classes, lr=0.1, reg=0.0):\n",
    "        self.W = np.zeros((n_features, n_classes))\n",
    "        self.b = np.zeros((1, n_classes))\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        logits = X.dot(self.W) + self.b\n",
    "        return softmax(logits)\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return np.argmax(probs, axis=1)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None, epochs=100, batch_size=256, verbose=True):\n",
    "        n, d = X.shape\n",
    "        classes = np.unique(y)\n",
    "        C = len(classes)\n",
    "        label_to_idx = {v: i for i, v in enumerate(classes)}\n",
    "        idx_to_label = {i: v for v, i in label_to_idx.items()}\n",
    "        y_idx = np.array([label_to_idx[v] for v in y])\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            perm = np.random.permutation(n)\n",
    "            X_sh = X[perm]\n",
    "            y_sh = y_idx[perm]\n",
    "            for i in range(0, n, batch_size):\n",
    "                X_batch = X_sh[i:i + batch_size]\n",
    "                y_batch = y_sh[i:i + batch_size]\n",
    "                m = len(X_batch)\n",
    "                probs = softmax(X_batch.dot(self.W) + self.b)\n",
    "                y_onehot = one_hot(y_batch, C)\n",
    "                grad_logits = (probs - y_onehot) / m\n",
    "                gradW = X_batch.T.dot(grad_logits) + self.reg * self.W\n",
    "                gradb = np.sum(grad_logits, axis=0, keepdims=True)\n",
    "                self.W -= self.lr * gradW\n",
    "                self.b -= self.lr * gradb\n",
    "\n",
    "            # Track validation accuracy\n",
    "            if verbose and epoch % max(1, epochs // 10) == 0:\n",
    "                preds_train = np.argmax(softmax(X.dot(self.W) + self.b), axis=1)\n",
    "                acc_train = np.mean(preds_train == y_idx)\n",
    "                if X_val is not None and y_val is not None:\n",
    "                    preds_val = np.argmax(softmax(X_val.dot(self.W) + self.b), axis=1)\n",
    "                    acc_val = np.mean(preds_val == np.array([label_to_idx[v] for v in y_val]))\n",
    "                    print(f\"Epoch {epoch}/{epochs} - Train acc: {acc_train:.4f}, Val acc: {acc_val:.4f}\")\n",
    "                else:\n",
    "                    print(f\"Epoch {epoch}/{epochs} - Train acc: {acc_train:.4f}\")\n",
    "\n",
    "        self._label_to_idx = label_to_idx\n",
    "        self._idx_to_label = idx_to_label\n",
    "\n",
    "    def predict_labels(self, X):\n",
    "        idxs = self.predict(X)\n",
    "        return np.array([self._idx_to_label[i] for i in idxs])\n",
    "\n",
    "# ===============================\n",
    "# 4ï¸âƒ£ MNIST Loader\n",
    "# ===============================\n",
    "def load_mnist_csv(path, label_col='label'):\n",
    "    df = pd.read_csv(path)\n",
    "    possible_labels = ['label', 'Label', 'digit', 'target']\n",
    "    if label_col not in df.columns:\n",
    "        for c in possible_labels:\n",
    "            if c in df.columns:\n",
    "                label_col = c\n",
    "                break\n",
    "\n",
    "    if label_col in df.columns:\n",
    "        y = df[label_col].astype(int).values\n",
    "        X = df.drop(columns=[label_col]).values\n",
    "    else:\n",
    "        y = None\n",
    "        X = df.values\n",
    "\n",
    "    X = X.astype(float)\n",
    "    if X.max() > 1.0:\n",
    "        X /= 255.0\n",
    "    return X, y\n",
    "\n",
    "# ===============================\n",
    "# 5ï¸âƒ£ Split Data (Train/Val)\n",
    "# ===============================\n",
    "def train_val_split(X, y, val_ratio=0.2, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    n = len(y)\n",
    "    indices = np.random.permutation(n)\n",
    "    val_size = int(n * val_ratio)\n",
    "    val_idx = indices[:val_size]\n",
    "    train_idx = indices[val_size:]\n",
    "    return X[train_idx], X[val_idx], y[train_idx], y[val_idx]\n",
    "\n",
    "# ===============================\n",
    "# 6ï¸âƒ£ Training + Prediction Workflow\n",
    "# ===============================\n",
    "def run_mnist_training(train_csv, test_csv, epochs=50):\n",
    "    # Load train data and split into train/val\n",
    "    X_train_full, y_train_full = load_mnist_csv(train_csv)\n",
    "    X_train, X_val, y_train, y_val = train_val_split(X_train_full, y_train_full, val_ratio=0.2)\n",
    "\n",
    "    X_test, _ = load_mnist_csv(test_csv)\n",
    "\n",
    "    print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "    n_features = X_train.shape[1]\n",
    "    n_classes = len(np.unique(y_train))\n",
    "\n",
    "    model = SoftmaxRegression(n_features=n_features, n_classes=n_classes, lr=0.5, reg=1e-4)\n",
    "    model.fit(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=512)\n",
    "\n",
    "    # Validation evaluation\n",
    "    y_val_pred = model.predict_labels(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    metrics = precision_recall_f1(y_val, y_val_pred)\n",
    "    print(\"\\n=== Validation Metrics ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    for lbl, p, r, f in zip(metrics[\"labels\"], metrics[\"precision\"], metrics[\"recall\"], metrics[\"f1\"]):\n",
    "        print(f\"Class {lbl}: Precision={p:.3f}, Recall={r:.3f}, F1={f:.3f}\")\n",
    "\n",
    "    # Predict for unlabeled test set\n",
    "    y_test_pred = model.predict_labels(X_test)\n",
    "    print(\"\\nâœ… Predictions for test.csv completed!\")\n",
    "    print(f\"Total test samples: {len(y_test_pred)}\")\n",
    "    print(\"Example predictions:\", y_test_pred[:10])\n",
    "\n",
    "    # Save predictions\n",
    "    output = pd.DataFrame({'ImageId': np.arange(1, len(y_test_pred) + 1), 'Label': y_test_pred})\n",
    "    output.to_csv(\"mnist_test_predictions.csv\", index=False)\n",
    "    print(\"Predictions saved as 'mnist_test_predictions.csv'\")\n",
    "\n",
    "    return model, (X_val, y_val, X_test, y_test_pred)\n",
    "\n",
    "# ===============================\n",
    "# 7ï¸âƒ£ Prediction for Single Image\n",
    "# ===============================\n",
    "def predict_image_and_label(flat_pixels, model):\n",
    "    arr = np.array(flat_pixels).astype(float)\n",
    "    if arr.max() > 1.0:\n",
    "        arr /= 255.0\n",
    "    img = array_to_image((arr * 255).astype(np.uint8))\n",
    "    pred_label = model.predict_labels(arr.reshape(1, -1))[0]\n",
    "    return img, pred_label\n",
    "\n",
    "# ===============================\n",
    "# âœ… Example Usage\n",
    "# ===============================\n",
    "# model, (X_val, y_val, X_test, y_test_pred) = run_mnist_training(\n",
    "#     \"MNIST_data/train.csv\", \"MNIST_data/test.csv\", epochs=30)\n",
    "# img, label = predict_image_and_label(X_test[0], model)\n",
    "# img.show()\n",
    "# print(\"Predicted:\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a98c4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (33600, 784), Val shape: (8400, 784), Test shape: (28000, 784)\n",
      "Epoch 3/30 - Train acc: 0.9066, Val acc: 0.8987\n",
      "Epoch 3/30 - Train acc: 0.9066, Val acc: 0.8987\n",
      "Epoch 6/30 - Train acc: 0.9125, Val acc: 0.9096\n",
      "Epoch 6/30 - Train acc: 0.9125, Val acc: 0.9096\n",
      "Epoch 9/30 - Train acc: 0.9190, Val acc: 0.9140\n",
      "Epoch 9/30 - Train acc: 0.9190, Val acc: 0.9140\n",
      "Epoch 12/30 - Train acc: 0.9222, Val acc: 0.9136\n",
      "Epoch 12/30 - Train acc: 0.9222, Val acc: 0.9136\n",
      "Epoch 15/30 - Train acc: 0.9238, Val acc: 0.9152\n",
      "Epoch 15/30 - Train acc: 0.9238, Val acc: 0.9152\n",
      "Epoch 18/30 - Train acc: 0.9252, Val acc: 0.9161\n",
      "Epoch 18/30 - Train acc: 0.9252, Val acc: 0.9161\n",
      "Epoch 21/30 - Train acc: 0.9257, Val acc: 0.9180\n",
      "Epoch 21/30 - Train acc: 0.9257, Val acc: 0.9180\n",
      "Epoch 24/30 - Train acc: 0.9271, Val acc: 0.9154\n",
      "Epoch 24/30 - Train acc: 0.9271, Val acc: 0.9154\n",
      "Epoch 27/30 - Train acc: 0.9284, Val acc: 0.9171\n",
      "Epoch 27/30 - Train acc: 0.9284, Val acc: 0.9171\n",
      "Epoch 30/30 - Train acc: 0.9276, Val acc: 0.9160\n",
      "\n",
      "=== Validation Metrics ===\n",
      "Accuracy: 0.9160\n",
      "Class 0: Precision=0.960, Recall=0.966, F1=0.963\n",
      "Class 1: Precision=0.953, Recall=0.978, F1=0.965\n",
      "Class 2: Precision=0.913, Recall=0.894, F1=0.903\n",
      "Class 3: Precision=0.903, Recall=0.875, F1=0.889\n",
      "Class 4: Precision=0.915, Recall=0.930, F1=0.923\n",
      "Class 5: Precision=0.842, Recall=0.872, F1=0.857\n",
      "Class 6: Precision=0.932, Recall=0.955, F1=0.943\n",
      "Class 7: Precision=0.929, Recall=0.920, F1=0.925\n",
      "Class 8: Precision=0.921, Recall=0.860, F1=0.889\n",
      "Class 9: Precision=0.882, Recall=0.906, F1=0.893\n",
      "\n",
      "âœ… Predictions for test.csv completed!\n",
      "Total test samples: 28000\n",
      "Example predictions: [2 0 9 7 3 7 0 3 0 3]\n",
      "Predictions saved as 'mnist_test_predictions.csv'\n",
      "Predicted: 2\n",
      "Epoch 30/30 - Train acc: 0.9276, Val acc: 0.9160\n",
      "\n",
      "=== Validation Metrics ===\n",
      "Accuracy: 0.9160\n",
      "Class 0: Precision=0.960, Recall=0.966, F1=0.963\n",
      "Class 1: Precision=0.953, Recall=0.978, F1=0.965\n",
      "Class 2: Precision=0.913, Recall=0.894, F1=0.903\n",
      "Class 3: Precision=0.903, Recall=0.875, F1=0.889\n",
      "Class 4: Precision=0.915, Recall=0.930, F1=0.923\n",
      "Class 5: Precision=0.842, Recall=0.872, F1=0.857\n",
      "Class 6: Precision=0.932, Recall=0.955, F1=0.943\n",
      "Class 7: Precision=0.929, Recall=0.920, F1=0.925\n",
      "Class 8: Precision=0.921, Recall=0.860, F1=0.889\n",
      "Class 9: Precision=0.882, Recall=0.906, F1=0.893\n",
      "\n",
      "âœ… Predictions for test.csv completed!\n",
      "Total test samples: 28000\n",
      "Example predictions: [2 0 9 7 3 7 0 3 0 3]\n",
      "Predictions saved as 'mnist_test_predictions.csv'\n",
      "Predicted: 2\n"
     ]
    }
   ],
   "source": [
    "model, (X_val, y_val, X_test, y_test_pred) = run_mnist_training(\n",
    "    \"MNIST_data/train.csv\", \"MNIST_data/test.csv\", epochs=30)\n",
    "img, label = predict_image_and_label(X_test[0], model)\n",
    "img.show()\n",
    "print(\"Predicted:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from math import log, pi, exp\n",
    "\n",
    "# =========================\n",
    "# Utility metric functions\n",
    "# =========================\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(np.array(y_true) == np.array(y_pred))\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    label_to_idx = {v:i for i,v in enumerate(labels)}\n",
    "    cm = np.zeros((len(labels), len(labels)), dtype=int)\n",
    "    for t,p in zip(y_true, y_pred):\n",
    "        cm[label_to_idx[t], label_to_idx[p]] += 1\n",
    "    return labels, cm\n",
    "\n",
    "def precision_recall_f1(y_true, y_pred):\n",
    "    labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    metrics = {}\n",
    "    for label in labels:\n",
    "        tp = np.sum((y_pred == label) & (y_true == label))\n",
    "        fp = np.sum((y_pred == label) & (y_true != label))\n",
    "        fn = np.sum((y_pred != label) & (y_true == label))\n",
    "        prec = tp / (tp + fp) if (tp + fp) else 0\n",
    "        rec = tp / (tp + fn) if (tp + fn) else 0\n",
    "        f1 = 2 * prec * rec / (prec + rec) if (prec + rec) else 0\n",
    "        metrics[label] = {'precision': prec, 'recall': rec, 'f1': f1}\n",
    "    return metrics\n",
    "\n",
    "# =========================\n",
    "# Naive Bayes Classifier\n",
    "# =========================\n",
    "class NaiveBayesMixed:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha  # Laplace smoothing for categorical\n",
    "        self.classes = None\n",
    "        self.cat_features = []\n",
    "        self.num_features = []\n",
    "        self.class_priors = {}\n",
    "        self.cat_cond_probs = {}  # P(x|y) for categorical\n",
    "        self.num_params = {}      # mean, var for numeric\n",
    "\n",
    "    def _gaussian_log_prob(self, x, mean, var):\n",
    "        var = max(var, 1e-6)\n",
    "        return -0.5 * log(2 * pi * var) - ((x - mean)**2) / (2 * var)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        df = X.copy()\n",
    "        df['y'] = y\n",
    "        self.classes = np.unique(y)\n",
    "        cols = X.columns\n",
    "\n",
    "        # Separate feature types\n",
    "        for col in cols:\n",
    "            if pd.api.types.is_numeric_dtype(X[col]):\n",
    "                self.num_features.append(col)\n",
    "            else:\n",
    "                self.cat_features.append(col)\n",
    "\n",
    "        # Class priors\n",
    "        self.class_priors = {cls: np.log(np.mean(y == cls)) for cls in self.classes}\n",
    "\n",
    "        # Numeric feature parameters\n",
    "        self.num_params = {col: {} for col in self.num_features}\n",
    "        for col in self.num_features:\n",
    "            for cls in self.classes:\n",
    "                vals = df.loc[df['y'] == cls, col].astype(float)\n",
    "                self.num_params[col][cls] = (vals.mean(), vals.var(ddof=0))\n",
    "\n",
    "        # Categorical feature probabilities\n",
    "        self.cat_cond_probs = {col: {} for col in self.cat_features}\n",
    "        for col in self.cat_features:\n",
    "            values = X[col].astype(str).unique()\n",
    "            V = len(values)\n",
    "            for cls in self.classes:\n",
    "                subset = df.loc[df['y'] == cls, col].astype(str)\n",
    "                counts = subset.value_counts().to_dict()\n",
    "                total = len(subset)\n",
    "                probs = {}\n",
    "                for val in values:\n",
    "                    probs[val] = log((counts.get(val, 0) + self.alpha) / (total + self.alpha * V))\n",
    "                self.cat_cond_probs[col][cls] = probs\n",
    "\n",
    "    def _predict_row(self, row):\n",
    "        log_probs = {}\n",
    "        for cls in self.classes:\n",
    "            log_prob = self.class_priors[cls]\n",
    "            # Numeric features\n",
    "            for col in self.num_features:\n",
    "                x = float(row[col])\n",
    "                mean, var = self.num_params[col][cls]\n",
    "                log_prob += self._gaussian_log_prob(x, mean, var)\n",
    "            # Categorical features\n",
    "            for col in self.cat_features:\n",
    "                val = str(row[col])\n",
    "                if val in self.cat_cond_probs[col][cls]:\n",
    "                    log_prob += self.cat_cond_probs[col][cls][val]\n",
    "                else:\n",
    "                    # unseen category\n",
    "                    V = len(self.cat_cond_probs[col][cls])\n",
    "                    log_prob += log(self.alpha / (self.alpha * V))\n",
    "            log_probs[cls] = log_prob\n",
    "        return max(log_probs, key=log_probs.get)\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = [self._predict_row(row) for _, row in X.iterrows()]\n",
    "        return np.array(preds)\n",
    "\n",
    "# =========================\n",
    "# Data Split Function\n",
    "# =========================\n",
    "def stratified_split(df, target='y', test_size=0.3, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    train_idx, test_idx = [], []\n",
    "    for cls, subset in df.groupby(target):\n",
    "        idx = subset.index.to_numpy()\n",
    "        np.random.shuffle(idx)\n",
    "        n_test = int(len(idx) * test_size)\n",
    "        test_idx.extend(idx[:n_test])\n",
    "        train_idx.extend(idx[n_test:])\n",
    "    return df.loc[train_idx].reset_index(drop=True), df.loc[test_idx].reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# Run Naive Bayes on bank-full.csv\n",
    "# =========================\n",
    "def run_bank_naive_bayes(file_path=\"bank-full.csv\"):\n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    train_df, test_df = stratified_split(df, target='y', test_size=0.3)\n",
    "\n",
    "    X_train, y_train = train_df.drop(columns=['y']), train_df['y'].values\n",
    "    X_test, y_test = test_df.drop(columns=['y']), test_df['y'].values\n",
    "\n",
    "    model = NaiveBayesMixed(alpha=1.0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    metrics = precision_recall_f1(y_test, y_pred)\n",
    "    labels, cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n=== Naive Bayes Evaluation on bank-full.csv ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    for lbl, vals in metrics.items():\n",
    "        print(f\"{lbl}: Precision={vals['precision']:.3f}, Recall={vals['recall']:.3f}, F1={vals['f1']:.3f}\")\n",
    "    print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
    "    print(pd.DataFrame(cm, index=labels, columns=labels))\n",
    "\n",
    "    return model, (X_test, y_test, y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "819cd80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Naive Bayes Evaluation on bank-full.csv ===\n",
      "Accuracy: 0.8667\n",
      "no: Precision=0.935, Recall=0.912, F1=0.924\n",
      "yes: Precision=0.441, Recall=0.521, F1=0.477\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "        no   yes\n",
      "no   10928  1048\n",
      "yes    760   826\n"
     ]
    }
   ],
   "source": [
    "model, (X_test, y_test, y_pred) = run_bank_naive_bayes(\"bank-full.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bdcd2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# ===============================\n",
    "# Reuse your function\n",
    "# ===============================\n",
    "def array_to_image(arr, size=(28, 28)):\n",
    "    \"\"\"Convert a flat array (784 pixels) into a 28x28 grayscale PIL Image.\"\"\"\n",
    "    a = np.array(arr).astype(np.uint8).reshape(size)\n",
    "    return Image.fromarray(a)\n",
    "\n",
    "# ===============================\n",
    "# Load MNIST CSV\n",
    "# ===============================\n",
    "# ðŸ”¹ Update this path to where your MNIST CSV actually is\n",
    "mnist_train = pd.read_csv(\"MNIST_data/train.csv\")\n",
    "\n",
    "# Separate labels and pixel arrays\n",
    "labels = mnist_train['label'].values\n",
    "images = mnist_train.drop(columns=['label']).values\n",
    "\n",
    "# ===============================\n",
    "# Visualize a few random samples\n",
    "# ===============================\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0, len(images))  # pick a random sample\n",
    "    img_array = images[idx]\n",
    "    label = labels[idx]\n",
    "    \n",
    "    # Use your custom function\n",
    "    img = array_to_image(img_array)\n",
    "    \n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca5703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
